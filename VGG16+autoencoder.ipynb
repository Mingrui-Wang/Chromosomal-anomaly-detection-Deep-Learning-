{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16+autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOqPm8l2yWQYA+QTS9Atbh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mingrui-Wang/Inverse-of-a-Matrix/blob/master/VGG16%2Bautoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtCTQL58Mr8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/暑期科研/\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYza0pZ1Q1sU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "52deff98-1f1d-4f21-d256-ebe6bb26c7d1"
      },
      "source": [
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout, UpSampling2D\n",
        "import os\n",
        "\n",
        "x_train_savepath = './训练集.npy'\n",
        "y_train_savepath = './训练集_label.npy'\n",
        "\n",
        "x_test_savepath = './测试集.npy'\n",
        "y_test_savepath = './测试集_label.npy'\n",
        "print('-------------Load Datasets-----------------')\n",
        "x_train = np.load(x_train_savepath)\n",
        "y_train = np.load(y_train_savepath)\n",
        "x_test = np.load(x_test_savepath)\n",
        "y_test = np.load(y_test_savepath)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------Load Datasets-----------------\n",
            "(2129, 22500)\n",
            "(230, 22500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7drZVTrtnZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "2966df32-81e4-4632-ece0-4c6875c098cc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(\"x_train.shape\", x_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], 150, 150, 1)  # 给数据增加一个维度，使数据和网络结构匹配\n",
        "x_test = x_test.reshape(x_test.shape[0], 150, 150, 1)\n",
        "print(\"x_train.shape\", x_train.shape)\n",
        "\n",
        "\n",
        "class VGG16(Model):\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.c1 = Conv2D(filters=64, kernel_size=(3, 3), padding='same')  # 卷积层1\n",
        "        self.b1 = BatchNormalization()  # BN层1\n",
        "        self.a1 = Activation('relu')  # 激活层1\n",
        "        self.c2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same', )\n",
        "        self.b2 = BatchNormalization()  # BN层1\n",
        "        self.a2 = Activation('relu')  # 激活层1\n",
        "        self.p1 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d1 = Dropout(0.2)  # dropout层\n",
        "\n",
        "        self.c3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')\n",
        "        self.b3 = BatchNormalization()  # BN层1\n",
        "        self.a3 = Activation('relu')  # 激活层1\n",
        "        self.c4 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')\n",
        "        self.b4 = BatchNormalization()  # BN层1\n",
        "        self.a4 = Activation('relu')  # 激活层1\n",
        "        self.p2 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d2 = Dropout(0.2)  # dropout层\n",
        "\n",
        "        self.c5 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')\n",
        "        self.b5 = BatchNormalization()  # BN层1\n",
        "        self.a5 = Activation('relu')  # 激活层1\n",
        "        self.c6 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')\n",
        "        self.b6 = BatchNormalization()  # BN层1\n",
        "        self.a6 = Activation('relu')  # 激活层1\n",
        "        self.c7 = Conv2D(filters=256, kernel_size=(3, 3), padding='same')\n",
        "        self.b7 = BatchNormalization()\n",
        "        self.a7 = Activation('relu')\n",
        "        self.p3 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d3 = Dropout(0.2)\n",
        "\n",
        "        self.c8 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b8 = BatchNormalization()  # BN层1\n",
        "        self.a8 = Activation('relu')  # 激活层1\n",
        "        self.c9 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b9 = BatchNormalization()  # BN层1\n",
        "        self.a9 = Activation('relu')  # 激活层1\n",
        "        self.c10 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b10 = BatchNormalization()\n",
        "        self.a10 = Activation('relu')\n",
        "        self.p4 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d4 = Dropout(0.2)\n",
        "\n",
        "        self.c11 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b11 = BatchNormalization()  # BN层1\n",
        "        self.a11 = Activation('relu')  # 激活层1\n",
        "        self.c12 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b12 = BatchNormalization()  # BN层1\n",
        "        self.a12 = Activation('relu')  # 激活层1\n",
        "        self.c13 = Conv2D(filters=512, kernel_size=(3, 3), padding='same')\n",
        "        self.b13 = BatchNormalization()\n",
        "        self.a13 = Activation('relu')\n",
        "        self.p5 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
        "        self.d5 = Dropout(0.2)\n",
        "\n",
        "        self.flatten = Flatten()\n",
        "        self.f1 = Dense(512, activation='relu')\n",
        "        self.d6 = Dropout(0.2)\n",
        "        self.f2 = Dense(512, activation='relu')\n",
        "        self.d7 = Dropout(0.2)\n",
        "        self.f3 = Dense(2, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.c1(x)\n",
        "        x = self.b1(x)\n",
        "        x = self.a1(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.b2(x)\n",
        "        x = self.a2(x)\n",
        "        x = self.p1(x)\n",
        "        x = self.d1(x)\n",
        "\n",
        "        x = self.c3(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.a3(x)\n",
        "        x = self.c4(x)\n",
        "        x = self.b4(x)\n",
        "        x = self.a4(x)\n",
        "        x = self.p2(x)\n",
        "        x = self.d2(x)\n",
        "\n",
        "        x = self.c5(x)\n",
        "        x = self.b5(x)\n",
        "        x = self.a5(x)\n",
        "        x = self.c6(x)\n",
        "        x = self.b6(x)\n",
        "        x = self.a6(x)\n",
        "        x = self.c7(x)\n",
        "        x = self.b7(x)\n",
        "        x = self.a7(x)\n",
        "        x = self.p3(x)\n",
        "        x = self.d3(x)\n",
        "\n",
        "        x = self.c8(x)\n",
        "        x = self.b8(x)\n",
        "        x = self.a8(x)\n",
        "        x = self.c9(x)\n",
        "        x = self.b9(x)\n",
        "        x = self.a9(x)\n",
        "        x = self.c10(x)\n",
        "        x = self.b10(x)\n",
        "        x = self.a10(x)\n",
        "        x = self.p4(x)\n",
        "        x = self.d4(x)\n",
        "\n",
        "        x = self.c11(x)\n",
        "        x = self.b11(x)\n",
        "        x = self.a11(x)\n",
        "        x = self.c12(x)\n",
        "        x = self.b12(x)\n",
        "        x = self.a12(x)\n",
        "        x = self.c13(x)\n",
        "        x = self.b13(x)\n",
        "        x = self.a13(x)\n",
        "        x = self.p5(x)\n",
        "        x = self.d5(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.f1(x)\n",
        "        x = self.d6(x)\n",
        "        x = self.f2(x)\n",
        "        x = self.d7(x)\n",
        "        y = self.f3(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "model = VGG16()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "checkpoint_save_path = \"./checkpoint/VGG16.ckpt\"\n",
        "if os.path.exists(checkpoint_save_path + '.index'):\n",
        "    print('-------------load the model-----------------')\n",
        "    model.load_weights(checkpoint_save_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
        "                          save_weights_only=True,\n",
        "                          save_best_only=True)\n",
        "\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=16, epochs=40, validation_data=(x_test, y_test), validation_freq=1,\n",
        "                    callbacks=[cp_callback])\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape (2129, 22500)\n",
            "x_train.shape (2129, 150, 150, 1)\n",
            "Epoch 1/40\n",
            "  2/134 [..............................] - ETA: 9s - loss: 0.2513 - sparse_categorical_accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0528s vs `on_train_batch_end` time: 0.0864s). Check your callbacks.\n",
            "134/134 [==============================] - 22s 164ms/step - loss: 0.9311 - sparse_categorical_accuracy: 0.9009 - val_loss: 0.3605 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 2/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.9277 - val_loss: 21.0990 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 3/40\n",
            "134/134 [==============================] - 20s 146ms/step - loss: 0.1510 - sparse_categorical_accuracy: 0.9634 - val_loss: 13.3504 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 4/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1472 - sparse_categorical_accuracy: 0.9676 - val_loss: 9.2939 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 5/40\n",
            "134/134 [==============================] - 19s 144ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9634 - val_loss: 1.0003 - val_sparse_categorical_accuracy: 0.4478\n",
            "Epoch 6/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9671 - val_loss: 1.3474 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 7/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9713 - val_loss: 2.2385 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 8/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1484 - sparse_categorical_accuracy: 0.9615 - val_loss: 16.5922 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 9/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1375 - sparse_categorical_accuracy: 0.9709 - val_loss: 1.9092 - val_sparse_categorical_accuracy: 0.2174\n",
            "Epoch 10/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1199 - sparse_categorical_accuracy: 0.9713 - val_loss: 4.7154 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 11/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9723 - val_loss: 2.8529 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 12/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9704 - val_loss: 2.6724 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 13/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9760 - val_loss: 3.3929 - val_sparse_categorical_accuracy: 0.0870\n",
            "Epoch 14/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9760 - val_loss: 1.8576 - val_sparse_categorical_accuracy: 0.0870\n",
            "Epoch 15/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.9704 - val_loss: 1.6891 - val_sparse_categorical_accuracy: 0.0870\n",
            "Epoch 16/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.8942 - val_sparse_categorical_accuracy: 0.6696\n",
            "Epoch 17/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9760 - val_loss: 11.6826 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 18/40\n",
            "134/134 [==============================] - 20s 146ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9723 - val_loss: 2.6556 - val_sparse_categorical_accuracy: 0.1478\n",
            "Epoch 19/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9676 - val_loss: 34.2477 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 20/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9760 - val_loss: 51.5119 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 21/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9779 - val_loss: 14.2831 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 22/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.0962 - sparse_categorical_accuracy: 0.9751 - val_loss: 12.8683 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 23/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9760 - val_loss: 25.5795 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 24/40\n",
            "134/134 [==============================] - 19s 145ms/step - loss: 0.0746 - sparse_categorical_accuracy: 0.9817 - val_loss: 16.3771 - val_sparse_categorical_accuracy: 0.9130\n",
            "Epoch 25/40\n",
            " 85/134 [==================>...........] - ETA: 6s - loss: 0.0921 - sparse_categorical_accuracy: 0.9750"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UQlqz4XntXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "afd43093-0d81-417b-dca3-f672e24690ac"
      },
      "source": [
        "x_train_savepath = './N_A_H.npy'\n",
        "print('-------------Load Datasets-----------------')\n",
        "x_train_save = np.load(x_train_savepath)\n",
        "x_train = np.reshape(x_train_save, (len(x_train_save), 150, 150,1))\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "\n",
        "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------Load Datasets-----------------\n",
            "(2359, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy35odsfSvGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "01ecb26b-2bf7-4e8c-82aa-6852aa9bfbf6"
      },
      "source": [
        "xnp.argmax(model.predict(x_test), axis=1))\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b132365e5b8d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    xnp.argmax(model.predict(x_test), axis=1))\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}